nohup: 忽略输入
train.py:28: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(
/home/zhangyusi/.conda/envs/idp3/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'mmidp3.yaml': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/home/zhangyusi/.conda/envs/idp3/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/zhangyusi/Improved-3D-Diffusion-Policy/Improved-3D-Diffusion-Policy/diffusion_policy_3d/workspace/mmidp3_workspace.py:337: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(
/home/zhangyusi/.conda/envs/idp3/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/home/zhangyusi/.conda/envs/idp3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/zhangyusi/.conda/envs/idp3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
Training:   0%|          | 0/301 [00:00<?, ?it/s]Training:   0%|          | 1/301 [53:11<265:58:38, 3191.73s/it]Training:   1%|          | 2/301 [1:14:11<170:42:32, 2055.36s/it]Training:   1%|          | 3/301 [1:30:11<128:44:20, 1555.24s/it]Training:   1%|▏         | 4/301 [1:41:35<99:54:56, 1211.10s/it] Training:   2%|▏         | 5/301 [2:01:46<99:35:28, 1211.24s/it]Training:   2%|▏         | 6/301 [2:33:53<119:10:34, 1454.35s/it]Training:   2%|▏         | 7/301 [2:41:00<91:20:52, 1118.54s/it] Training:   3%|▎         | 8/301 [2:48:06<73:05:16, 898.01s/it] Training:   3%|▎         | 9/301 [3:11:49<86:09:41, 1062.26s/it]Training:   3%|▎         | 10/301 [3:39:36<100:57:41, 1249.01s/it]Training:   4%|▎         | 11/301 [4:09:47<114:27:50, 1420.93s/it]Training:   4%|▍         | 12/301 [4:37:02<119:17:18, 1485.95s/it]Training:   4%|▍         | 13/301 [5:07:24<127:02:22, 1587.99s/it]Training:   5%|▍         | 14/301 [5:38:34<133:22:45, 1673.05s/it]Training:   5%|▍         | 15/301 [6:28:47<164:59:39, 2076.85s/it]Training:   5%|▌         | 16/301 [7:18:17<185:43:13, 2345.94s/it]Training:   6%|▌         | 17/301 [7:51:24<176:32:07, 2237.77s/it]Training:   6%|▌         | 18/301 [8:34:15<183:47:03, 2337.89s/it]Training:   6%|▋         | 19/301 [9:23:59<198:21:10, 2532.16s/it]Training:   7%|▋         | 20/301 [10:16:28<212:06:15, 2717.35s/it]Training:   7%|▋         | 21/301 [10:59:54<208:45:05, 2683.95s/it]Training:   7%|▋         | 22/301 [11:44:00<207:07:14, 2672.52s/it]Training:   8%|▊         | 23/301 [12:19:06<193:15:16, 2502.58s/it]Training:   8%|▊         | 24/301 [12:57:42<188:14:04, 2446.37s/it]Training:   8%|▊         | 25/301 [13:35:27<183:23:12, 2392.00s/it]Training:   9%|▊         | 26/301 [14:20:44<190:10:28, 2489.56s/it]Training:   9%|▉         | 27/301 [15:17:10<209:56:41, 2758.40s/it]train_mmidp3_policy_marsmind_episode.sh: 行 52: 28770 已杀死               python train.py --config-name=${config_name}.yaml task=${task_name} hydra.run.dir=${run_dir} training.debug=$DEBUG training.seed=${seed} training.device="cuda:0" exp_name=${exp_name} logging.mode=${wandb_mode} checkpoint.save_ckpt=${save_ckpt} task.dataset.data_path=$dataset_path task.dataset.task_name=Cruise_A
